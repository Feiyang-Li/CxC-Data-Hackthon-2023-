{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Voting method is the combination of logistic regression, support vector machine, kernel ridge regression, nearest Neighbors, Gaussian processes, Decision Tree\n",
    "##  And with linear regression to train for the weight of each method vote, and the combine voting of these model yield result that should\n",
    "#   incorporate the advantageous of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Bagging ++\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# KNeighbour\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "# Ada Boost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# neural network for classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../DataSet/with4_train.csv\") # trainig data\n",
    "valid = pd.read_csv(\"../DataSet/with4_valid.csv\") # validation data\n",
    "\n",
    "X_train, y_train = train.iloc[:,:-1],train.iloc[:,-1] # split the y from other columns\n",
    "X_valid, y_valid = valid.iloc[:,:-1],valid.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48322350002153597\n"
     ]
    }
   ],
   "source": [
    "# logistic:\n",
    "logistic = LogisticRegression(random_state = 42)\n",
    "baging = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=10, random_state=42)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "Kn_neibour = KNeighborsClassifier()\n",
    "Support_vect = SVC()\n",
    "ada = AdaBoostClassifier(n_estimators=50) # need more in Ada case\n",
    "mlp = MLPClassifier(hidden_layer_sizes=30, activation=\"relu\", learning_rate_init=0.003)\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', logistic), ('bg', baging), ('dt', decision_tree), ('knn', Kn_neibour), ('svm', Support_vect), ('ab', ada)\n",
    "        # , ('mlp', mlp)\n",
    "    ],\n",
    "    voting=\"hard\"\n",
    ")\n",
    "\n",
    "eclf.fit(X_train, y_train)\n",
    "print(eclf.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state = 42)\n",
    "baging = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=10, random_state=42)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "Kn_neibour = KNeighborsClassifier()\n",
    "Support_vect = SVC()\n",
    "ada = AdaBoostClassifier(n_estimators=200) # need more in Ada case\n",
    "mlp = MLPClassifier(hidden_layer_sizes=30, activation=\"relu\", max_iter=5000, learning_rate_init=0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5237972175561011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(random_state = 42)\n",
    "logistic.fit(X_train, y_train)\n",
    "logistic.score(X_valid, y_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5741805573502176\n",
      "0.5688611793082655\n",
      "0.5163780850239049\n",
      "0.5160658138433045\n",
      "0.5134491967093079\n",
      "0.512210879958651\n",
      "0.5039195417151225\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 40, 5):\n",
    "    baging = ExtraTreesClassifier(n_estimators=i, max_depth=None, min_samples_split=10, random_state=42)\n",
    "    baging.fit(X_train, y_train)\n",
    "    print(baging.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48322350002153597"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48322350002153597"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kn_neibour = KNeighborsClassifier()\n",
    "Kn_neibour.fit(X_train, y_train)\n",
    "Kn_neibour.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m Support_vect \u001b[39m=\u001b[39m SVC()\n\u001b[1;32m      2\u001b[0m Support_vect\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 3\u001b[0m Support_vect\u001b[39m.\u001b[39;49mscore(X_valid, y_valid)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:649\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 649\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    819\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    821\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    434\u001b[0m predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[0;32m--> 435\u001b[0m \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:454\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mX.shape[1] = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be equal to \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe number of samples at training time\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m             \u001b[39m%\u001b[39m (X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_[\u001b[39m0\u001b[39m])\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    452\u001b[0m svm_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m libsvm\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    455\u001b[0m     X,\n\u001b[1;32m    456\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_,\n\u001b[1;32m    457\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_,\n\u001b[1;32m    458\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_support,\n\u001b[1;32m    459\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dual_coef_,\n\u001b[1;32m    460\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_,\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probA,\n\u001b[1;32m    462\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probB,\n\u001b[1;32m    463\u001b[0m     svm_type\u001b[39m=\u001b[39;49msvm_type,\n\u001b[1;32m    464\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    465\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[1;32m    466\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[1;32m    467\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    468\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[1;32m    469\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Support_vect = SVC()\n",
    "Support_vect.fit(X_train, y_train)\n",
    "Support_vect.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48322350002153597"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=500)\n",
    "ada.fit(X_train, y_train)\n",
    "ada.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48322350002153597"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=30, activation=\"relu\", max_iter=5000, learning_rate_init=0.003)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48322350002153597\n",
      "0.48322350002153597\n",
      "0.5039195417151225\n",
      "0.5237972175561011\n"
     ]
    }
   ],
   "source": [
    "## Conduct training \n",
    "ada = AdaBoostClassifier(n_estimators=200)\n",
    "ada.fit(X_train, y_train)\n",
    "print(ada.score(X_valid, y_valid))\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "print(decision_tree.score(X_valid, y_valid))\n",
    "\n",
    "baging = ExtraTreesClassifier(n_estimators=i, max_depth=None, min_samples_split=10, random_state=42)\n",
    "baging.fit(X_train, y_train)\n",
    "print(baging.score(X_valid, y_valid))\n",
    "\n",
    "logistic = LogisticRegression(random_state = 42)\n",
    "logistic.fit(X_train, y_train)\n",
    "print(logistic.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49254856355256926\n",
      "0.5688611793082655\n",
      "0.49254856355256926\n",
      "0.49254856355256926\n",
      "0.5237972175561011\n",
      "0.49254856355256926\n",
      "0.49254856355256926\n",
      "0.49254856355256926\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=200)\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "baging = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=10, random_state=42)\n",
    "\n",
    "logistic = LogisticRegression(random_state = 42)\n",
    "\n",
    "for i in range(1, 3, 1):\n",
    "    for j in  range(1, 3, 1):\n",
    "        for k in range(1, 3, 1):\n",
    "            eclf = VotingClassifier(\n",
    "                estimators=[\n",
    "                    ('lr', logistic),  ('ab', ada), ('ET', baging)\n",
    "                    # , ('mlp', mlp)\n",
    "                ],\n",
    "                voting=\"hard\",\n",
    "                weights = [i,j,k]\n",
    "            )\n",
    "\n",
    "            eclf.fit(X_train, y_train)\n",
    "            print(eclf.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
